{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_full_name(json_array):\n",
    "    if isinstance(json_array, list) and len(json_array) > 0:\n",
    "        main_names = [obj for obj in json_array if obj.get('note') == 'Main']\n",
    "        main_names = json_array\n",
    "        if 'name' in main_names[-1]:\n",
    "            return main_names[-1]['name']\n",
    "        elif 'honorific_prefix' in main_names[-1] and 'lordname' in main_names[-1] and 'lordofname' in main_names[-1]:\n",
    "            if main_names[-1]['lordofname'] == '':\n",
    "                return main_names[-1]['honorific_prefix'] + ' ' + main_names[-1]['lordname']\n",
    "            else:\n",
    "                return main_names[-1]['honorific_prefix'] + ' ' + main_names[-1]['lordname'] + ' of ' + main_names[-1]['lordofname']\n",
    "        elif 'honorific_prefix' in main_names[-1] and 'given_name' in main_names[-1] and 'family_name' in main_names[-1]:\n",
    "            return main_names[-1]['honorific_prefix'] + ' ' + main_names[-1]['given_name'] + ' ' + main_names[-1]['family_name']\n",
    "        elif 'given_name' in main_names[-1] and 'lordname' in main_names[-1]:\n",
    "            return main_names[-1]['given_name'] + ' ' + main_names[-1]['lordname']\n",
    "        elif 'honorific_prefix' in main_names[-1] and 'family_name' in main_names[-1]:\n",
    "            return main_names[-1]['honorific_prefix'] + ' ' + main_names[-1]['family_name']\n",
    "        elif 'given_name' in main_names[-1] and 'family_name' in main_names[-1]:\n",
    "            return main_names[-1]['given_name'] + ' ' + main_names[-1]['family_name']\n",
    "        elif 'given_name' in main_names[-1]:\n",
    "            return main_names[-1]['given_name']\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def redirect_full_name(row):\n",
    "    if pd.isna(row['speaker_name']):\n",
    "        match = persons_df[persons_df['id'] == row['redirect']]\n",
    "        return match.iloc[0]['speaker_name']\n",
    "    else:\n",
    "        return row['speaker_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_df = pd.read_csv('intermediate_outputs/all_speeches.csv', parse_dates=['hdate'])\n",
    "person_dict = json.load(open('external_datasets/people.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "memberships_df = pd.DataFrame(person_dict['memberships'])\n",
    "memberships_df.rename({\n",
    "    'id': 'membership_id',\n",
    "    'on_behalf_of_id': 'party_id',\n",
    "    'start_date': 'membership_start_date',\n",
    "    'end_date': 'membership_end_date'\n",
    "    }, axis = 1, inplace = True)\n",
    "memberships_df.drop(['end_reason', 'identifiers', 'start_reason', 'label', 'role', 'redirect', 'reason', 'name', 'organization_id'], axis = 1, inplace = True)\n",
    "memberships_df.dropna(subset=['person_id'], inplace = True)\n",
    "\n",
    "parties_df = pd.DataFrame(person_dict['organizations'])\n",
    "parties_df.rename({\n",
    "    'id': 'party_id',\n",
    "    'name': 'party_name'\n",
    "    }, axis = 1, inplace = True)\n",
    "parties_df.drop(['classification', 'identifiers'], axis = 1, inplace = True)\n",
    "\n",
    "persons_df = pd.DataFrame(person_dict['persons'])\n",
    "persons_df['speaker_id'] = persons_df['id'].str.extract(r'(-?\\d+)$')\n",
    "persons_df['speaker_name'] = persons_df['other_names'].apply(lambda x: extract_full_name(x)).tolist()\n",
    "persons_df['speaker_name'] = persons_df.apply(redirect_full_name, axis=1)\n",
    "persons_df.rename({'id': 'person_id'}, axis = 1, inplace = True)\n",
    "persons_df.drop(['identifiers', 'other_names', 'shortcuts', 'redirect'], axis = 1, inplace = True)\n",
    "\n",
    "posts_df = pd.json_normalize(person_dict['posts'], sep = '_')\n",
    "posts_df.rename({\n",
    "    'id': 'post_id',\n",
    "    'label': 'post_name',\n",
    "    'area_name': 'post_area_name'\n",
    "    }, axis = 1, inplace = True)\n",
    "posts_df.drop(['identifiers', 'organization_id', 'role', 'start_date', 'end_date'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech_df:  (16436, 11)\n",
      "joined_1:  (16436, 13)\n",
      "joined_2:  (84652, 18)\n",
      "joined_3:  (16459, 18)\n",
      "Unique to joined_1: set()\n",
      "Unique to joined_3: set()\n",
      "multiple_membership:  (56, 18)\n",
      "joined_4:  (16459, 20)\n",
      "joined_5:  (16459, 21)\n",
      "speech_person_df:  (16436, 21)\n"
     ]
    }
   ],
   "source": [
    "print('speech_df: ', speech_df.shape)\n",
    "\n",
    "joined_1 = pd.merge(\n",
    "    speech_df,\n",
    "    persons_df,\n",
    "    how = 'left',\n",
    "    left_on = 'speaker_id',\n",
    "    right_on = 'speaker_id'\n",
    ")\n",
    "\n",
    "print('joined_1: ', joined_1.shape)\n",
    "\n",
    "joined_2 = pd.merge(\n",
    "    joined_1,\n",
    "    memberships_df,\n",
    "    how = 'left',\n",
    "    left_on = 'person_id',\n",
    "    right_on = 'person_id' # One to many join\n",
    ")\n",
    "\n",
    "print('joined_2: ', joined_2.shape)\n",
    "\n",
    "joined_3 = joined_2[\n",
    "    (joined_2['person_id'].isna()) |\n",
    "    (\n",
    "        (\n",
    "            (joined_2['hdate'] >=  joined_2['membership_start_date']) |\n",
    "            (joined_2['membership_start_date'].isna())\n",
    "        ) &\n",
    "        (\n",
    "            (joined_2['hdate'] <= joined_2['membership_end_date']) |\n",
    "            (joined_2['membership_end_date'].isna())\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "print('joined_3: ', joined_3.shape)\n",
    "\n",
    "# The shape difference is not due to missing speeches\n",
    "set_joined_1 = set(joined_1['gid']+joined_1['person_id'])\n",
    "set_joined_3 = set(joined_3['gid']+joined_3['person_id'])\n",
    "unique_to_joined_1 = set_joined_1 - set_joined_3\n",
    "unique_to_joined_3 = set_joined_3 - set_joined_1\n",
    "print(\"Unique to joined_1:\", unique_to_joined_1)\n",
    "print(\"Unique to joined_3:\", unique_to_joined_3)\n",
    "\n",
    "# The shape difference is due to speakers with multiple memberships in the same period. This will be resolved after all joins.\n",
    "multiple_membership = joined_3[joined_3['speech_body'].duplicated(keep=False)]\n",
    "multiple_membership = multiple_membership[multiple_membership['gid'].duplicated(keep=False)]\n",
    "print('multiple_membership: ', multiple_membership.shape)\n",
    "\n",
    "joined_4 = pd.merge(\n",
    "    joined_3,\n",
    "    posts_df,\n",
    "    how = 'left',\n",
    "    left_on = 'post_id',\n",
    "    right_on = 'post_id'\n",
    ")\n",
    "\n",
    "print('joined_4: ', joined_4.shape)\n",
    "\n",
    "joined_5 = pd.merge(\n",
    "    joined_4,\n",
    "    parties_df,\n",
    "    how = 'left',\n",
    "    left_on = 'party_id',\n",
    "    right_on = 'party_id'\n",
    ")\n",
    "\n",
    "print('joined_5: ', joined_5.shape)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "# Replace this with your actual DataFrame\n",
    "speech_person_df = pd.DataFrame({\n",
    "    # Your columns here\n",
    "})\n",
    "\n",
    "def unique_string_agg(series):\n",
    "    return ', '.join(sorted(set(series.dropna())))\n",
    "\n",
    "speech_person_df = joined_5.groupby(['gid', 'hdate', 'parent_body', 'file_name', 'html_file_name', 'debate_type', 'written_type', 'speech_body', 'full_url',\n",
    "       'relevant_speeches', 'speaker_id', 'person_id', 'speaker_name'], as_index = False, dropna = False).agg(unique_string_agg)\n",
    "\n",
    "print('speech_person_df: ', speech_person_df.shape) # Back to 16436 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_person_df.to_csv('all_speeches_and_person.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
